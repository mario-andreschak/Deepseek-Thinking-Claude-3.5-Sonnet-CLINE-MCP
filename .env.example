# API Provider Configuration
# You can use either OpenRouter for all models, or configure direct API access to specific providers

# Option 1: OpenRouter (recommended for easy access to multiple models)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Option 2: Direct API Access
# Uncomment and configure these if you want to use direct API access instead of OpenRouter

# Anthropic API (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# DeepSeek API
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# OpenAI API
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE_URL=https://api.openai.com/v1

# Google Gemini API
GEMINI_API_KEY=your_gemini_api_key_here

# Vertex AI (for Gemini models through Vertex AI)
VERTEX_PROJECT_ID=your_vertex_ai_project_id_here
VERTEX_REGION=your_vertex_ai_region_here

# Model Selection
# Configure which models to use for reasoning and coding tasks
# For OpenRouter, use the full model name (e.g., anthropic/claude-3.5-sonnet)
# For direct API access, use the model ID (e.g., claude-3-5-sonnet-20241022)
# The code initializes clients for
# - openrouter
# - anthropic
# - deepseek
# - openai
# - gemini 
# - vertex


# Reasoning Model (default: DeepSeek Reasoner)
REASONING_PROVIDER=deepseek  # Options: openrouter, anthropic, deepseek, openai
REASONING_MODEL=deepseek-reasoner

# Coding Model (default: Claude)
CODING_PROVIDER=openrouter  # Options: openrouter, anthropic, openai
CODING_MODEL=anthropic/claude-3.5-sonnet

# See src/providers.json for a complete list of available models and their capabilities
